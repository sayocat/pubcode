
# Python Training Code for “Sweets From India” Image classification  version 1.0.0

# Import necessary library modules and frameworks into Python.
import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt
import os 
import glob as gb
import cv2
import tensorflow  as tf 
import keras

# Check if the machine is ready to use your GPU
from tensorflow.python.client import device_lib
print('DEVICES', device_lib.list_local_devices())

# Define the paths to your datasets
trainpath='./datasets/sweetsfromindia/train'
testpath='./datasets/sweetsfromindia/test'

# List the number of image files in your datasets
for folder in os.listdir(trainpath):
    files=gb.glob(pathname=str(trainpath + '/'+folder + '/*.jpg'))
    print(f"numbers of images {len(files)} in {folder}")
for folder in os.listdir(testpath):
    files=gb.glob(pathname=str(testpath + '/'+folder + '/*.jpg'))
    print(f"numbers of images {len(files)} in {folder}")

# Check the image size of each image files in your datasets for training
size=[]
for folder in os.listdir(trainpath):
    files=gb.glob(pathname=str(trainpath + '/'+folder + '/*.jpg'))
    for file in files:
        image=plt.imread(file)
        size.append(image.shape)
pd.Series(size).value_counts()

# Define the labels
labels={'gulab_jamun':0,'halwa':1,'kaju_katli':2,'kheer':3}
def getcode(n):
    for x,y in labels.items():
        if n==y:
            return x

# Resize the image files to normalize the training data
x_train=[]
y_train=[]
for folder in os.listdir(trainpath):
    files=gb.glob(pathname=str(trainpath + '/'+folder + '/*.jpg'))
    for file in files:
        image=cv2.imread(file)
        img_arr=cv2.resize(image,(128,128))
        x_train.append(img_arr)
        y_train.append(labels[folder])

# Display the training images on your IDE
plt.figure(figsize=(13,13))
for n,i in enumerate(list(np.random.randint(0,len(x_train),30))):
    plt.subplot(5,6,n+1)
    plt.grid(False)
    plt.imshow(cv2.cvtColor(x_train[i], cv2.COLOR_BGR2RGB))
    plt.title(getcode(y_train[i]))
plt.show()

# Check the image size of each image files in your datasets for test
size=[]
for folder in os.listdir(testpath):
    files=gb.glob(pathname=str(testpath + '/'+folder + '/*.jpg'))
    for file in files:
        image=plt.imread(file)
        size.append(image.shape)
pd.Series(size).value_counts()

# Resize the image files to normalize the test data
x_test=[]
# y_test=[]
for folder in os.listdir(testpath):
    files=gb.glob(pathname=str(testpath + '/'+folder + '/*.jpg'))
    for file in files:
        image=cv2.imread(file)
        img_arr=cv2.resize(image,(128,128))
        x_test.append(img_arr)
        # y_test.append(labels[folder])

# Display the test images on your IDE
plt.figure(figsize=(13,13))
for n,i in enumerate(list(np.random.randint(0,len(x_test),30))):
    plt.subplot(5,6,n+1)
    plt.grid(False)
    plt.imshow(cv2.cvtColor(x_test[i], cv2.COLOR_BGR2RGB))
    plt.title('test')
plt.show()

# Check the size and the number of normalized data
x_train = np.array(x_train)
x_test = np.array(x_test)
y_train = np.array(y_train)
# y_test = np.array(y_test)
print(f'X_train shape  is {x_train.shape}')
print(f'X_test shape  is {x_test.shape}')
print(f'y_train shape  is {y_train.shape}')
# print(f'y_test shape  is {y_test.shape}')

# Define the training algorythm
sweets = keras.models.Sequential([
    keras.layers.Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(128,128,3)),
    keras.layers.Conv2D(64,kernel_size=(3,3),activation='relu'),
    keras.layers.MaxPool2D((2,2)),
    keras.layers.Conv2D(128,kernel_size=(3,3),activation='relu'),
    keras.layers.MaxPool2D((2,2)),
    keras.layers.Conv2D(256,kernel_size=(3,3),activation='relu'),
    keras.layers.MaxPool2D((2,2)),
    keras.layers.Flatten(),
    keras.layers.Dense(256,activation='relu'),
    keras.layers.Dense(192,activation='relu'),
    keras.layers.Dense(128,activation='relu'),
    keras.layers.Dense(64,activation='relu'),
    keras.layers.Dense(32,activation='relu'),
    keras.layers.Dropout(rate=0.5),
    keras.layers.Dense(16,activation='relu'),
    keras.layers.Dense(4,activation='softmax'),
 
])


# Display the summary of the model
sweets.summary()

# Compile the model
sweets.compile(optimizer='adam',
             loss='sparse_categorical_crossentropy',
             metrics=['accuracy'])

# Kick of the training then wait until the training completes
sweets.fit(x_train, y_train, epochs=10, batch_size=64)

# Evaluate the model
loss,acc=sweets.evaluate(x_train,y_train)
print(loss)
print(acc)

# Make sure to save the model
sweets.save('./models/sweetsfromindia.keras')

# Get prediction ready
sweets = tf.keras.Sequential([sweets,tf.keras.layers.Softmax()])
y_pred = sweets.predict(x_test)

# Select the image test file to perform online prediction
y_pred[0]

# Display the test image and get prediction together
labels=['gulab_jamun', 'halwa', 'kaju_katli', 'kheer']
image_number = 0
plt.imshow(cv2.cvtColor(x_test[image_number], cv2.COLOR_BGR2RGB))
predicted_label = labels[np.argmax(y_pred[image_number])]
print("Predicted label is {}".format(predicted_label))

from keras.models import load_model
sweets = load_model('./models/sweetsfromindia.keras')






# Author : Yoshiharu Sato
